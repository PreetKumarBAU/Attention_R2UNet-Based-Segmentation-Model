{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Attention-R2UNet.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:51.955926Z",
          "iopub.execute_input": "2021-07-02T11:06:51.956273Z",
          "iopub.status.idle": "2021-07-02T11:06:52.008001Z",
          "shell.execute_reply.started": "2021-07-02T11:06:51.956244Z",
          "shell.execute_reply": "2021-07-02T11:06:52.006807Z"
        },
        "trusted": true,
        "id": "QW3vJgl9LZFr"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, Permute, Activation, Input, \\\n",
        "    add, multiply\n",
        "from keras.layers import concatenate, core, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.core import Lambda\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def up_and_concate(down_layer, layer, data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        in_channel = down_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    else:\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_up_and_concate(down_layer, layer, data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        in_channel = down_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        in_channel = down_layer.get_shape().as_list()[3]\n",
        "\n",
        "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
        "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
        "\n",
        "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
        "\n",
        "    if data_format == 'channels_first':\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
        "    else:\n",
        "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
        "\n",
        "    concate = my_concat([up, layer])\n",
        "    return concate\n",
        "\n",
        "\n",
        "def attention_block_2d(x, g, inter_channel, data_format='channels_first'):\n",
        "    # theta_x(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
        "\n",
        "    # phi_g(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
        "\n",
        "    # f(?,g_height,g_width,inter_channel)\n",
        "\n",
        "    f = Activation('relu')(add([theta_x, phi_g]))\n",
        "\n",
        "    # psi_f(?,g_height,g_width,1)\n",
        "\n",
        "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
        "\n",
        "    rate = Activation('sigmoid')(psi_f)\n",
        "\n",
        "    # rate(?,x_height,x_width)\n",
        "\n",
        "    # att_x(?,x_height,x_width,x_channel)\n",
        "\n",
        "    att_x = multiply([x, rate])\n",
        "\n",
        "    return att_x\n",
        "\n",
        "\n",
        "def res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "\n",
        "              padding='same', data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
        "\n",
        "    layer = input_layer\n",
        "    for i in range(2):\n",
        "        layer = Conv2D(out_n_filters // 4, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "        if batch_normalization:\n",
        "            layer = BatchNormalization()(layer)\n",
        "        layer = Activation('relu')(layer)\n",
        "        layer = Conv2D(out_n_filters // 4, kernel_size, strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "        layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(layer)\n",
        "\n",
        "    if out_n_filters != input_n_filters:\n",
        "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
        "            input_layer)\n",
        "    else:\n",
        "        skip_layer = input_layer\n",
        "    out_layer = add([layer, skip_layer])\n",
        "    return out_layer\n",
        "\n",
        "\n",
        "# Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def rec_res_block(input_layer, out_n_filters, batch_normalization=False, kernel_size=[3, 3], stride=[1, 1],\n",
        "\n",
        "                  padding='same', data_format='channels_first'):\n",
        "    if data_format == 'channels_first':\n",
        "        input_n_filters = input_layer.get_shape().as_list()[1]\n",
        "    else:\n",
        "        input_n_filters = input_layer.get_shape().as_list()[3]\n",
        "\n",
        "    if out_n_filters != input_n_filters:\n",
        "        skip_layer = Conv2D(out_n_filters, [1, 1], strides=stride, padding=padding, data_format=data_format)(\n",
        "            input_layer)\n",
        "    else:\n",
        "        skip_layer = input_layer\n",
        "\n",
        "    layer = skip_layer\n",
        "    for j in range(2):\n",
        "\n",
        "        for i in range(2):\n",
        "            if i == 0:\n",
        "\n",
        "                layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
        "                    layer)\n",
        "                if batch_normalization:\n",
        "                    layer1 = BatchNormalization()(layer1)\n",
        "                layer1 = Activation('relu')(layer1)\n",
        "            layer1 = Conv2D(out_n_filters, kernel_size, strides=stride, padding=padding, data_format=data_format)(\n",
        "                add([layer1, layer]))\n",
        "            if batch_normalization:\n",
        "                layer1 = BatchNormalization()(layer1)\n",
        "            layer1 = Activation('relu')(layer1)\n",
        "        layer = layer1\n",
        "\n",
        "    out_layer = add([layer, skip_layer])\n",
        "    return out_layer\n",
        "\n",
        "########################################################################################################\n",
        "# Define the neural network\n",
        "def unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format= data_format)(x)\n",
        "        features = features * 2\n",
        "\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        # attention_up_and_concate(x,[skips[i])\n",
        "        x = UpSampling2D(size=(2, 2), data_format=data_format)(x)\n",
        "        x = concatenate([skips[i], x], axis=1)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "\n",
        "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Attention U-Net\n",
        "def att_unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format='channels_first')(x)\n",
        "        features = features * 2\n",
        "\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(features, (3, 3), activation='relu', padding='same', data_format=data_format)(x)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "\n",
        "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Recurrent Residual Convolutional Neural Network based on U-Net (R2U-Net)\n",
        "def r2_unet(img_w, img_h, n_label, data_format='channels_first'):\n",
        "    inputs = Input((3, img_w, img_h))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n",
        "\n",
        "        features = features * 2\n",
        "\n",
        "    x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n",
        "    return model\n",
        "\n",
        "\n",
        "########################################################################################################\n",
        "#Attention R2U-Net\n",
        "def att_r2_unet(img_w, img_h, n_label, data_format='channels_last'):\n",
        "    inputs = Input((img_w, img_h , 3))\n",
        "    x = inputs\n",
        "    depth = 4\n",
        "    features = 64\n",
        "    skips = []\n",
        "    for i in range(depth):\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "        skips.append(x)\n",
        "        x = MaxPooling2D((2, 2), data_format=data_format)(x)\n",
        "\n",
        "        features = features * 2\n",
        "\n",
        "    x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    for i in reversed(range(depth)):\n",
        "        features = features // 2\n",
        "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
        "        x = rec_res_block(x, features, data_format=data_format)\n",
        "\n",
        "    conv6 = Conv2D(n_label, (1, 1), padding='same', data_format=data_format)(x)\n",
        "    conv7 = core.Activation('sigmoid')(conv6)\n",
        "    model = Model(inputs=inputs, outputs=conv7)\n",
        "    #model.compile(optimizer=Adam(lr=1e-6), loss=[dice_coef_loss], metrics=['accuracy', dice_coef])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:52.010311Z",
          "iopub.execute_input": "2021-07-02T11:06:52.010885Z",
          "iopub.status.idle": "2021-07-02T11:06:52.015936Z",
          "shell.execute_reply.started": "2021-07-02T11:06:52.010842Z",
          "shell.execute_reply": "2021-07-02T11:06:52.014760Z"
        },
        "trusted": true,
        "id": "liAPRFIzLZFw"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:52.091941Z",
          "iopub.execute_input": "2021-07-02T11:06:52.092638Z",
          "iopub.status.idle": "2021-07-02T11:06:53.056741Z",
          "shell.execute_reply.started": "2021-07-02T11:06:52.092589Z",
          "shell.execute_reply": "2021-07-02T11:06:53.055934Z"
        },
        "trusted": true,
        "id": "ZnV3CHozLZFx",
        "outputId": "56c5fa70-a89f-44cd-eef0-38897573b743"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io # To read a single image\n",
        "\n",
        "datagen = ImageDataGenerator( #Randomly rotates but with atmost rotation as 45 degree , Randomly width is varied but with atmost 20% width change \n",
        "                        rotation_range = 45 , \n",
        "                        width_shift_range = 0.2,\n",
        "                        height_shift_range = 0.2 ,\n",
        "                        shear_range        = 0.2 , \n",
        "                        horizontal_flip = True , \n",
        "                        fill_mode = \"constant\" , cval = 125)\n",
        ")\n",
        "def load_data(paths , split = 0.15):\n",
        "  images = []\n",
        "  masks = []\n",
        "  numImages = 0\n",
        "  numMasks = 0\n",
        "\n",
        "  for path in paths:\n",
        "    \n",
        "        \n",
        "    images.extend(sorted(glob(os.path.join(path , \"images/*\"))))\n",
        "    masks.extend(sorted(glob(os.path.join(path , \"label/*\"))))\n",
        "    if \"training\" in path:\n",
        "      for i in [\"00\", \"01\" , \"02\" , \"03\" , \"04\" , \"05\" , \"07\", \"08\" , \"09\" , \"10\" , \"11\" , \"12\" , \"13\" , \"14\" , \"16\" , \"17\" , \"18\" , \"19\" , \"21\" , \"22\" , \"24\" , \"26\" , \"27\" ]:\n",
        "        images.remove(\"../input/chagas/ChagasTraining/training-20210525T143718Z-001/training/images/i8{}.xml\".format(i))\n",
        "\n",
        "      n = \"training\"\n",
        "    if \"Test\" in path:\n",
        "      n= \"Test\"\n",
        "    if \"Val\" in path:\n",
        "\n",
        "      n= \"Validation\"\n",
        "\n",
        "    print(\"{}PathImagesAre:\".format(n),len(images) - numImages)\n",
        "    print(\"{}PathImagesAre:\".format(n),len(masks) - numMasks)\n",
        "\n",
        "    numImages = len(images)\n",
        "    numMasks = len(masks)\n",
        "\n",
        "  total_size = len(images)\n",
        "  valid_size = int(split * total_size)\n",
        "  test_size = int(split * total_size)\n",
        "  print(\"Number of images in Total , Validation images and Test Images : \" , total_size , valid_size ,test_size  )\n",
        "\n",
        "  train_x , test_x = train_test_split(images , test_size = test_size , random_state = 42 )\n",
        "  train_y , test_y = train_test_split(masks , test_size = test_size , random_state = 42 )\n",
        "\n",
        "  train_x , valid_x = train_test_split(train_x , test_size = valid_size , random_state = 42 )\n",
        "  train_y , valid_y = train_test_split(train_y , test_size = valid_size , random_state = 42 )\n",
        "\n",
        "  return (train_x , train_y) , (valid_x , valid_y ) , (test_x , test_y) \n",
        "\n",
        "def read_image(path):\n",
        "  path = path.decode()\n",
        "  x = cv2.imread(path , cv2.IMREAD_COLOR)\n",
        "  #x = cv2.resize(x , (256 , 256))\n",
        "  x = x/255.0\n",
        "  #Size is 256 * 256 * 3\n",
        "\n",
        "  return x\n",
        "\n",
        "def read_mask(path):\n",
        "  path = path.decode()\n",
        "  x = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n",
        "  #x = cv2.resize(x , (256 , 256))\n",
        "  x = x/255.0\n",
        "  \n",
        "  #Size is 256 * 256\n",
        "  x = np.expand_dims(x , axis = -1)\n",
        "  #Size becames 256 * 256 * 1\n",
        "\n",
        "  return x\n",
        "\n",
        "def tf_parse(imagepath , maskpath):\n",
        "  def _parse(imagepath , maskpath):\n",
        "    x = read_image(imagepath)\n",
        "    y = read_mask(maskpath)\n",
        "\n",
        "    return x , y\n",
        "\n",
        "  x , y = tf.numpy_function(_parse , [imagepath , maskpath] , [tf.float64 , tf.float64] )\n",
        "  x.set_shape([512 , 512 , 3])\n",
        "  y.set_shape([512, 512, 1])\n",
        "\n",
        "  return x , y \n",
        "\n",
        "\n",
        "def tf_dataset( imagepath , maskpath , batch = 2):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((imagepath , maskpath))\n",
        "  dataset = dataset.map(tf_parse)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  paths = [\"../input/chagas/ChagasTraining/training-20210525T143718Z-001/training\" , \"../input/chagas/ChagasTest/Test\", \"../input/chagas/ChagasValidation/Validation\"] \n",
        "  (train_x , train_y) , (valid_x , valid_y ) , (test_x , test_y)  =   load_data(paths)\n",
        "\n",
        "  print(\"Number of images in Train , Validation images and Test Images : \" ,len(train_x) , len(valid_x ) , len(test_x) )\n",
        "\n",
        "  ds = tf_dataset(test_x , test_y)\n",
        "  for x, y in ds:\n",
        "    \n",
        "    print(x.shape , y.shape)\n",
        "    break\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "trainingPathImagesAre: 600\ntrainingPathImagesAre: 600\nTestPathImagesAre: 200\nTestPathImagesAre: 200\nValidationPathImagesAre: 200\nValidationPathImagesAre: 200\nNumber of images in Total , Validation images and Test Images :  1000 150 150\nNumber of images in Train , Validation images and Test Images :  700 150 150\n(2, 512, 512, 3) (2, 512, 512, 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:53.059873Z",
          "iopub.execute_input": "2021-07-02T11:06:53.060150Z",
          "iopub.status.idle": "2021-07-02T11:06:53.066509Z",
          "shell.execute_reply.started": "2021-07-02T11:06:53.060124Z",
          "shell.execute_reply": "2021-07-02T11:06:53.065604Z"
        },
        "trusted": true,
        "id": "jw-8wmSwLZF0"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:53.069652Z",
          "iopub.execute_input": "2021-07-02T11:06:53.070018Z",
          "iopub.status.idle": "2021-07-02T11:06:53.078460Z",
          "shell.execute_reply.started": "2021-07-02T11:06:53.069986Z",
          "shell.execute_reply": "2021-07-02T11:06:53.077787Z"
        },
        "trusted": true,
        "id": "h15uGbrfLZF0"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
        "from tensorflow.keras.metrics import Recall , Precision \n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:53.079341Z",
          "iopub.execute_input": "2021-07-02T11:06:53.080523Z",
          "iopub.status.idle": "2021-07-02T11:06:58.580752Z",
          "shell.execute_reply.started": "2021-07-02T11:06:53.080493Z",
          "shell.execute_reply": "2021-07-02T11:06:58.579670Z"
        },
        "trusted": true,
        "id": "oCxUYw4BLZF0",
        "outputId": "2aa72832-32de-4c8a-cd09-34a4cc02e786"
      },
      "source": [
        "pip install segmentation_models\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: segmentation_models in /opt/conda/lib/python3.7/site-packages (1.0.1)\nRequirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.8)\nRequirement already satisfied: image-classifiers==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: efficientnet==1.0.0 in /opt/conda/lib/python3.7/site-packages (from segmentation_models) (1.0.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.1)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.2.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.3.17)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.4)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.0)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:58.586116Z",
          "iopub.execute_input": "2021-07-02T11:06:58.588324Z",
          "iopub.status.idle": "2021-07-02T11:06:58.599012Z",
          "shell.execute_reply.started": "2021-07-02T11:06:58.588277Z",
          "shell.execute_reply": "2021-07-02T11:06:58.597993Z"
        },
        "trusted": true,
        "id": "yAbjykHHLZF1",
        "outputId": "9a4885d2-2a2d-47d0-dd19-9ad22396b48b"
      },
      "source": [
        "%env SM_FRAMEWORK=tf.keras\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "env: SM_FRAMEWORK=tf.keras\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:58.604081Z",
          "iopub.execute_input": "2021-07-02T11:06:58.605577Z",
          "iopub.status.idle": "2021-07-02T11:06:58.632026Z",
          "shell.execute_reply.started": "2021-07-02T11:06:58.605536Z",
          "shell.execute_reply": "2021-07-02T11:06:58.630921Z"
        },
        "trusted": true,
        "id": "3UY_NHZeLZF1"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "def dice_coeff(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coeff(y_true, y_pred)\n",
        "    return loss\n",
        "def iou_coeff(y_true, y_pred):\n",
        "    smooth=1.\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union=K.sum(y_true_f) + K.sum(y_pred_f)-intersection\n",
        "    mvalue=(intersection+smooth)/(union+smooth)\n",
        "    return mvalue\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "    Only computes a batch-wise average of precision.\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "def ACL5(y_true, y_pred): \n",
        "\n",
        "    #y_pred = K.cast(y_pred, dtype = 'float64')\n",
        "\n",
        "    print(K.int_shape(y_pred))\n",
        "\n",
        "    x = y_pred[:,1:,:,:] - y_pred[:,:-1,:,:] # horizontal and vertical directions \n",
        "    y = y_pred[:,:,1:,:] - y_pred[:,:,:-1,:]\n",
        "\n",
        "    delta_x = x[:,1:,:-2,:]**2\n",
        "    delta_y = y[:,:-2,1:,:]**2\n",
        "    delta_u = K.abs(delta_x + delta_y) \n",
        "\n",
        "    epsilon = 0.00000001 # where is a parameter to avoid square root is zero in practice.\n",
        "    w = 1####\n",
        "    lenth = w * K.sum(K.sqrt(delta_u + epsilon)) # equ.(11) in the paper\n",
        "\n",
        "\n",
        "    C_1 = tf.ones((512, 512))\n",
        "    C_2 = tf.zeros((512, 512))\n",
        "\n",
        "    region_in = K.abs(K.sum( y_pred[:,:,:,0] * ((y_true[:,:,:,0] - C_1)**2) ) ) # equ.(12) in the paper\n",
        "    region_out = K.abs(K.sum( (1-y_pred[:,:,:,0]) * ((y_true[:,:,:,0] - C_2)**2) )) # equ.(12) in the paper\n",
        "\n",
        "    lambdaP = 5 # lambda parameter could be various.\n",
        "    \n",
        "    loss =  lenth + lambdaP * ((region_in) + (region_out)) \n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:58.637325Z",
          "iopub.execute_input": "2021-07-02T11:06:58.639628Z",
          "iopub.status.idle": "2021-07-02T11:06:59.894016Z",
          "shell.execute_reply.started": "2021-07-02T11:06:58.639586Z",
          "shell.execute_reply": "2021-07-02T11:06:59.893098Z"
        },
        "trusted": true,
        "id": "vnh3lNbiLZF1",
        "outputId": "95e063cc-ed72-4dbe-8392-17ec532e2c33"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    img_w, img_h, n_label = 512 , 512 , 1\n",
        "    model = att_r2_unet(img_w, img_h, n_label, data_format='channels_last')\n",
        "    \n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 512, 512, 64) 256         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       conv2d[0][0]                     \n__________________________________________________________________________________________________\nactivation (Activation)         (None, 512, 512, 64) 0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nadd (Add)                       (None, 512, 512, 64) 0           activation[0][0]                 \n                                                                 conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 512, 512, 64) 36928       add[0][0]                        \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 512, 512, 64) 0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 512, 512, 64) 0           activation_1[0][0]               \n                                                                 conv2d[0][0]                     \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 512, 512, 64) 36928       add_1[0][0]                      \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 512, 512, 64) 0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 512, 512, 64) 36928       activation_2[0][0]               \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 512, 512, 64) 0           conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 512, 512, 64) 0           activation_3[0][0]               \n                                                                 activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 512, 512, 64) 36928       add_2[0][0]                      \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 512, 512, 64) 0           conv2d_5[0][0]                   \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 512, 512, 64) 0           activation_4[0][0]               \n                                                                 activation_2[0][0]               \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 512, 512, 64) 36928       add_3[0][0]                      \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 512, 512, 64) 0           conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 512, 512, 64) 0           activation_5[0][0]               \n                                                                 conv2d[0][0]                     \n__________________________________________________________________________________________________\nmax_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           add_4[0][0]                      \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 256, 256, 128 8320        max_pooling2d[0][0]              \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 256, 256, 128 147584      conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 256, 256, 128 0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 256, 256, 128 0           activation_6[0][0]               \n                                                                 conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 256, 256, 128 147584      add_5[0][0]                      \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 256, 256, 128 0           conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 256, 256, 128 0           activation_7[0][0]               \n                                                                 conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 256, 256, 128 147584      add_6[0][0]                      \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 256, 256, 128 0           conv2d_10[0][0]                  \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 256, 256, 128 147584      activation_8[0][0]               \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 256, 256, 128 0           conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 256, 256, 128 0           activation_9[0][0]               \n                                                                 activation_8[0][0]               \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 256, 256, 128 147584      add_7[0][0]                      \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 256, 256, 128 0           conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 256, 256, 128 0           activation_10[0][0]              \n                                                                 activation_8[0][0]               \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 256, 256, 128 147584      add_8[0][0]                      \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 256, 256, 128 0           conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 256, 256, 128 0           activation_11[0][0]              \n                                                                 conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 128, 128, 256 33024       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 128, 128, 256 590080      conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 128, 128, 256 0           conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 128, 128, 256 0           activation_12[0][0]              \n                                                                 conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 128, 128, 256 590080      add_10[0][0]                     \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 128, 128, 256 0           conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 128, 128, 256 0           activation_13[0][0]              \n                                                                 conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 128, 128, 256 590080      add_11[0][0]                     \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 128, 128, 256 0           conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 128, 128, 256 590080      activation_14[0][0]              \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 128, 128, 256 0           conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 128, 128, 256 0           activation_15[0][0]              \n                                                                 activation_14[0][0]              \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 128, 128, 256 590080      add_12[0][0]                     \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 128, 128, 256 0           conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 128, 128, 256 0           activation_16[0][0]              \n                                                                 activation_14[0][0]              \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 128, 128, 256 590080      add_13[0][0]                     \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 128, 128, 256 0           conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 128, 128, 256 0           activation_17[0][0]              \n                                                                 conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           add_14[0][0]                     \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 64, 64, 512)  131584      max_pooling2d_2[0][0]            \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 64, 64, 512)  0           conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 64, 64, 512)  0           activation_18[0][0]              \n                                                                 conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 64, 64, 512)  2359808     add_15[0][0]                     \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 64, 64, 512)  0           conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 64, 64, 512)  0           activation_19[0][0]              \n                                                                 conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 64, 64, 512)  2359808     add_16[0][0]                     \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 64, 64, 512)  0           conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 64, 64, 512)  2359808     activation_20[0][0]              \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 64, 64, 512)  0           conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nadd_17 (Add)                    (None, 64, 64, 512)  0           activation_21[0][0]              \n                                                                 activation_20[0][0]              \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 64, 64, 512)  2359808     add_17[0][0]                     \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 64, 64, 512)  0           conv2d_26[0][0]                  \n__________________________________________________________________________________________________\nadd_18 (Add)                    (None, 64, 64, 512)  0           activation_22[0][0]              \n                                                                 activation_20[0][0]              \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 64, 64, 512)  2359808     add_18[0][0]                     \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 64, 64, 512)  0           conv2d_27[0][0]                  \n__________________________________________________________________________________________________\nadd_19 (Add)                    (None, 64, 64, 512)  0           activation_23[0][0]              \n                                                                 conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           add_19[0][0]                     \n__________________________________________________________________________________________________\nconv2d_28 (Conv2D)              (None, 32, 32, 1024) 525312      max_pooling2d_3[0][0]            \n__________________________________________________________________________________________________\nconv2d_29 (Conv2D)              (None, 32, 32, 1024) 9438208     conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 32, 32, 1024) 0           conv2d_29[0][0]                  \n__________________________________________________________________________________________________\nadd_20 (Add)                    (None, 32, 32, 1024) 0           activation_24[0][0]              \n                                                                 conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nconv2d_30 (Conv2D)              (None, 32, 32, 1024) 9438208     add_20[0][0]                     \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 32, 32, 1024) 0           conv2d_30[0][0]                  \n__________________________________________________________________________________________________\nadd_21 (Add)                    (None, 32, 32, 1024) 0           activation_25[0][0]              \n                                                                 conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nconv2d_31 (Conv2D)              (None, 32, 32, 1024) 9438208     add_21[0][0]                     \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 32, 32, 1024) 0           conv2d_31[0][0]                  \n__________________________________________________________________________________________________\nconv2d_32 (Conv2D)              (None, 32, 32, 1024) 9438208     activation_26[0][0]              \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 32, 32, 1024) 0           conv2d_32[0][0]                  \n__________________________________________________________________________________________________\nadd_22 (Add)                    (None, 32, 32, 1024) 0           activation_27[0][0]              \n                                                                 activation_26[0][0]              \n__________________________________________________________________________________________________\nconv2d_33 (Conv2D)              (None, 32, 32, 1024) 9438208     add_22[0][0]                     \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 32, 32, 1024) 0           conv2d_33[0][0]                  \n__________________________________________________________________________________________________\nadd_23 (Add)                    (None, 32, 32, 1024) 0           activation_28[0][0]              \n                                                                 activation_26[0][0]              \n__________________________________________________________________________________________________\nconv2d_34 (Conv2D)              (None, 32, 32, 1024) 9438208     add_23[0][0]                     \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 32, 32, 1024) 0           conv2d_34[0][0]                  \n__________________________________________________________________________________________________\nadd_24 (Add)                    (None, 32, 32, 1024) 0           activation_29[0][0]              \n                                                                 conv2d_28[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (None, 64, 64, 1024) 0           add_24[0][0]                     \n__________________________________________________________________________________________________\nconv2d_35 (Conv2D)              (None, 64, 64, 256)  131328      add_19[0][0]                     \n__________________________________________________________________________________________________\nconv2d_36 (Conv2D)              (None, 64, 64, 256)  262400      up_sampling2d[0][0]              \n__________________________________________________________________________________________________\nadd_25 (Add)                    (None, 64, 64, 256)  0           conv2d_35[0][0]                  \n                                                                 conv2d_36[0][0]                  \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 64, 64, 256)  0           add_25[0][0]                     \n__________________________________________________________________________________________________\nconv2d_37 (Conv2D)              (None, 64, 64, 1)    257         activation_30[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 64, 64, 1)    0           conv2d_37[0][0]                  \n__________________________________________________________________________________________________\nmultiply (Multiply)             (None, 64, 64, 512)  0           add_19[0][0]                     \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nlambda (Lambda)                 (None, 64, 64, 1536) 0           up_sampling2d[0][0]              \n                                                                 multiply[0][0]                   \n__________________________________________________________________________________________________\nconv2d_38 (Conv2D)              (None, 64, 64, 512)  786944      lambda[0][0]                     \n__________________________________________________________________________________________________\nconv2d_39 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 64, 64, 512)  0           conv2d_39[0][0]                  \n__________________________________________________________________________________________________\nadd_26 (Add)                    (None, 64, 64, 512)  0           activation_32[0][0]              \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nconv2d_40 (Conv2D)              (None, 64, 64, 512)  2359808     add_26[0][0]                     \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 64, 64, 512)  0           conv2d_40[0][0]                  \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 64, 64, 512)  0           activation_33[0][0]              \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nconv2d_41 (Conv2D)              (None, 64, 64, 512)  2359808     add_27[0][0]                     \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 64, 64, 512)  0           conv2d_41[0][0]                  \n__________________________________________________________________________________________________\nconv2d_42 (Conv2D)              (None, 64, 64, 512)  2359808     activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 64, 64, 512)  0           conv2d_42[0][0]                  \n__________________________________________________________________________________________________\nadd_28 (Add)                    (None, 64, 64, 512)  0           activation_35[0][0]              \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nconv2d_43 (Conv2D)              (None, 64, 64, 512)  2359808     add_28[0][0]                     \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 64, 64, 512)  0           conv2d_43[0][0]                  \n__________________________________________________________________________________________________\nadd_29 (Add)                    (None, 64, 64, 512)  0           activation_36[0][0]              \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nconv2d_44 (Conv2D)              (None, 64, 64, 512)  2359808     add_29[0][0]                     \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 64, 64, 512)  0           conv2d_44[0][0]                  \n__________________________________________________________________________________________________\nadd_30 (Add)                    (None, 64, 64, 512)  0           activation_37[0][0]              \n                                                                 conv2d_38[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (None, 128, 128, 512 0           add_30[0][0]                     \n__________________________________________________________________________________________________\nconv2d_45 (Conv2D)              (None, 128, 128, 128 32896       add_14[0][0]                     \n__________________________________________________________________________________________________\nconv2d_46 (Conv2D)              (None, 128, 128, 128 65664       up_sampling2d_1[0][0]            \n__________________________________________________________________________________________________\nadd_31 (Add)                    (None, 128, 128, 128 0           conv2d_45[0][0]                  \n                                                                 conv2d_46[0][0]                  \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 128, 128, 128 0           add_31[0][0]                     \n__________________________________________________________________________________________________\nconv2d_47 (Conv2D)              (None, 128, 128, 1)  129         activation_38[0][0]              \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 128, 128, 1)  0           conv2d_47[0][0]                  \n__________________________________________________________________________________________________\nmultiply_1 (Multiply)           (None, 128, 128, 256 0           add_14[0][0]                     \n                                                                 activation_39[0][0]              \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 128, 128, 768 0           up_sampling2d_1[0][0]            \n                                                                 multiply_1[0][0]                 \n__________________________________________________________________________________________________\nconv2d_48 (Conv2D)              (None, 128, 128, 256 196864      lambda_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_49 (Conv2D)              (None, 128, 128, 256 590080      conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 128, 128, 256 0           conv2d_49[0][0]                  \n__________________________________________________________________________________________________\nadd_32 (Add)                    (None, 128, 128, 256 0           activation_40[0][0]              \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nconv2d_50 (Conv2D)              (None, 128, 128, 256 590080      add_32[0][0]                     \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 128, 128, 256 0           conv2d_50[0][0]                  \n__________________________________________________________________________________________________\nadd_33 (Add)                    (None, 128, 128, 256 0           activation_41[0][0]              \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nconv2d_51 (Conv2D)              (None, 128, 128, 256 590080      add_33[0][0]                     \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 128, 128, 256 0           conv2d_51[0][0]                  \n__________________________________________________________________________________________________\nconv2d_52 (Conv2D)              (None, 128, 128, 256 590080      activation_42[0][0]              \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 128, 128, 256 0           conv2d_52[0][0]                  \n__________________________________________________________________________________________________\nadd_34 (Add)                    (None, 128, 128, 256 0           activation_43[0][0]              \n                                                                 activation_42[0][0]              \n__________________________________________________________________________________________________\nconv2d_53 (Conv2D)              (None, 128, 128, 256 590080      add_34[0][0]                     \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 128, 128, 256 0           conv2d_53[0][0]                  \n__________________________________________________________________________________________________\nadd_35 (Add)                    (None, 128, 128, 256 0           activation_44[0][0]              \n                                                                 activation_42[0][0]              \n__________________________________________________________________________________________________\nconv2d_54 (Conv2D)              (None, 128, 128, 256 590080      add_35[0][0]                     \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 128, 128, 256 0           conv2d_54[0][0]                  \n__________________________________________________________________________________________________\nadd_36 (Add)                    (None, 128, 128, 256 0           activation_45[0][0]              \n                                                                 conv2d_48[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           add_36[0][0]                     \n__________________________________________________________________________________________________\nconv2d_55 (Conv2D)              (None, 256, 256, 64) 8256        add_9[0][0]                      \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 256, 256, 64) 16448       up_sampling2d_2[0][0]            \n__________________________________________________________________________________________________\nadd_37 (Add)                    (None, 256, 256, 64) 0           conv2d_55[0][0]                  \n                                                                 conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 256, 256, 64) 0           add_37[0][0]                     \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 256, 256, 1)  65          activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 256, 256, 1)  0           conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nmultiply_2 (Multiply)           (None, 256, 256, 128 0           add_9[0][0]                      \n                                                                 activation_47[0][0]              \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 256, 256, 384 0           up_sampling2d_2[0][0]            \n                                                                 multiply_2[0][0]                 \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 256, 256, 128 49280       lambda_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 256, 256, 128 147584      conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 256, 256, 128 0           conv2d_59[0][0]                  \n__________________________________________________________________________________________________\nadd_38 (Add)                    (None, 256, 256, 128 0           activation_48[0][0]              \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 256, 256, 128 147584      add_38[0][0]                     \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 256, 256, 128 0           conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nadd_39 (Add)                    (None, 256, 256, 128 0           activation_49[0][0]              \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nconv2d_61 (Conv2D)              (None, 256, 256, 128 147584      add_39[0][0]                     \n__________________________________________________________________________________________________\nactivation_50 (Activation)      (None, 256, 256, 128 0           conv2d_61[0][0]                  \n__________________________________________________________________________________________________\nconv2d_62 (Conv2D)              (None, 256, 256, 128 147584      activation_50[0][0]              \n__________________________________________________________________________________________________\nactivation_51 (Activation)      (None, 256, 256, 128 0           conv2d_62[0][0]                  \n__________________________________________________________________________________________________\nadd_40 (Add)                    (None, 256, 256, 128 0           activation_51[0][0]              \n                                                                 activation_50[0][0]              \n__________________________________________________________________________________________________\nconv2d_63 (Conv2D)              (None, 256, 256, 128 147584      add_40[0][0]                     \n__________________________________________________________________________________________________\nactivation_52 (Activation)      (None, 256, 256, 128 0           conv2d_63[0][0]                  \n__________________________________________________________________________________________________\nadd_41 (Add)                    (None, 256, 256, 128 0           activation_52[0][0]              \n                                                                 activation_50[0][0]              \n__________________________________________________________________________________________________\nconv2d_64 (Conv2D)              (None, 256, 256, 128 147584      add_41[0][0]                     \n__________________________________________________________________________________________________\nactivation_53 (Activation)      (None, 256, 256, 128 0           conv2d_64[0][0]                  \n__________________________________________________________________________________________________\nadd_42 (Add)                    (None, 256, 256, 128 0           activation_53[0][0]              \n                                                                 conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d_3 (UpSampling2D)  (None, 512, 512, 128 0           add_42[0][0]                     \n__________________________________________________________________________________________________\nconv2d_65 (Conv2D)              (None, 512, 512, 32) 2080        add_4[0][0]                      \n__________________________________________________________________________________________________\nconv2d_66 (Conv2D)              (None, 512, 512, 32) 4128        up_sampling2d_3[0][0]            \n__________________________________________________________________________________________________\nadd_43 (Add)                    (None, 512, 512, 32) 0           conv2d_65[0][0]                  \n                                                                 conv2d_66[0][0]                  \n__________________________________________________________________________________________________\nactivation_54 (Activation)      (None, 512, 512, 32) 0           add_43[0][0]                     \n__________________________________________________________________________________________________\nconv2d_67 (Conv2D)              (None, 512, 512, 1)  33          activation_54[0][0]              \n__________________________________________________________________________________________________\nactivation_55 (Activation)      (None, 512, 512, 1)  0           conv2d_67[0][0]                  \n__________________________________________________________________________________________________\nmultiply_3 (Multiply)           (None, 512, 512, 64) 0           add_4[0][0]                      \n                                                                 activation_55[0][0]              \n__________________________________________________________________________________________________\nlambda_3 (Lambda)               (None, 512, 512, 192 0           up_sampling2d_3[0][0]            \n                                                                 multiply_3[0][0]                 \n__________________________________________________________________________________________________\nconv2d_68 (Conv2D)              (None, 512, 512, 64) 12352       lambda_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_69 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nactivation_56 (Activation)      (None, 512, 512, 64) 0           conv2d_69[0][0]                  \n__________________________________________________________________________________________________\nadd_44 (Add)                    (None, 512, 512, 64) 0           activation_56[0][0]              \n                                                                 conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nconv2d_70 (Conv2D)              (None, 512, 512, 64) 36928       add_44[0][0]                     \n__________________________________________________________________________________________________\nactivation_57 (Activation)      (None, 512, 512, 64) 0           conv2d_70[0][0]                  \n__________________________________________________________________________________________________\nadd_45 (Add)                    (None, 512, 512, 64) 0           activation_57[0][0]              \n                                                                 conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nconv2d_71 (Conv2D)              (None, 512, 512, 64) 36928       add_45[0][0]                     \n__________________________________________________________________________________________________\nactivation_58 (Activation)      (None, 512, 512, 64) 0           conv2d_71[0][0]                  \n__________________________________________________________________________________________________\nconv2d_72 (Conv2D)              (None, 512, 512, 64) 36928       activation_58[0][0]              \n__________________________________________________________________________________________________\nactivation_59 (Activation)      (None, 512, 512, 64) 0           conv2d_72[0][0]                  \n__________________________________________________________________________________________________\nadd_46 (Add)                    (None, 512, 512, 64) 0           activation_59[0][0]              \n                                                                 activation_58[0][0]              \n__________________________________________________________________________________________________\nconv2d_73 (Conv2D)              (None, 512, 512, 64) 36928       add_46[0][0]                     \n__________________________________________________________________________________________________\nactivation_60 (Activation)      (None, 512, 512, 64) 0           conv2d_73[0][0]                  \n__________________________________________________________________________________________________\nadd_47 (Add)                    (None, 512, 512, 64) 0           activation_60[0][0]              \n                                                                 activation_58[0][0]              \n__________________________________________________________________________________________________\nconv2d_74 (Conv2D)              (None, 512, 512, 64) 36928       add_47[0][0]                     \n__________________________________________________________________________________________________\nactivation_61 (Activation)      (None, 512, 512, 64) 0           conv2d_74[0][0]                  \n__________________________________________________________________________________________________\nadd_48 (Add)                    (None, 512, 512, 64) 0           activation_61[0][0]              \n                                                                 conv2d_68[0][0]                  \n__________________________________________________________________________________________________\nconv2d_75 (Conv2D)              (None, 512, 512, 1)  65          add_48[0][0]                     \n__________________________________________________________________________________________________\nactivation_62 (Activation)      (None, 512, 512, 1)  0           conv2d_75[0][0]                  \n==================================================================================================\nTotal params: 96,509,733\nTrainable params: 96,509,733\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:06:59.895318Z",
          "iopub.execute_input": "2021-07-02T11:06:59.895684Z",
          "iopub.status.idle": "2021-07-02T11:15:30.181783Z",
          "shell.execute_reply.started": "2021-07-02T11:06:59.895645Z",
          "shell.execute_reply": "2021-07-02T11:15:30.180593Z"
        },
        "trusted": true,
        "id": "CGjIf9Q8LZF2",
        "outputId": "d65c75a7-d1a1-488c-b3cb-d8cdb79ec8b8"
      },
      "source": [
        "import segmentation_models\n",
        "if __name__ == \"__main__\":\n",
        "    from segmentation_models.losses import bce_jaccard_loss\n",
        "    from segmentation_models.metrics import iou_score\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "    #HYPERPARAMETER\n",
        "\n",
        "\n",
        "    batch = 2\n",
        "    lr = 8.00E-05\n",
        "    epochs = 2\n",
        "    opt = tf.keras.optimizers.Adam(lr)\n",
        "    metrics = [\"acc\" , Recall() , Precision() , iou]\n",
        "    #Data\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n",
        "    img_w, img_h, n_label = 512 , 512 , 1\n",
        "    model = att_r2_unet(img_w, img_h, n_label, data_format='channels_last')\n",
        "    #final_output , model = build_model((512 , 512 , 3))\n",
        "    #model.summary()\n",
        "    #model.compile(loss=bce_jaccard_loss, optimizer=opt, metrics=metrics)\n",
        "    model.compile(optimizer= opt, loss=bce_jaccard_loss, metrics=[dice_loss,iou_coeff,precision,recall])\n",
        "    \n",
        "    callbacks = [ \n",
        "        ModelCheckpoint(\"files/model.h5\"),\n",
        "        ReduceLROnPlateau(monitor='iou', factor=0.1, patience=4),\n",
        "        #CSVLogger(\"/content/drive/MyDrive/data.csv\"),\n",
        "        TensorBoard(),\n",
        "        EarlyStopping(monitor='iou', patience=15, restore_best_weights=False)\n",
        "    ]\n",
        "    #Number Of Batches\n",
        "    train_steps = len(train_x)//batch\n",
        "    valid_steps = len(valid_x)//batch\n",
        "\n",
        "    if len(train_x) % batch != 0:\n",
        "        train_steps += 1\n",
        "    if len(valid_x) % batch != 0:\n",
        "        valid_steps += 1\n",
        "\n",
        "    model.fit(train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks,\n",
        "        shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Segmentation Models: using `tf.keras` framework.\nEpoch 1/2\n350/350 [==============================] - 256s 711ms/step - loss: 1.0154 - dice_loss: 0.8507 - iou_coeff: 0.0951 - precision: 0.2142 - recall: 0.1673 - val_loss: 0.5629 - val_dice_loss: 0.3617 - val_iou_coeff: 0.4815 - val_precision: 0.7249 - val_recall: 0.6418\nEpoch 2/2\n350/350 [==============================] - 248s 709ms/step - loss: 0.6153 - dice_loss: 0.4088 - iou_coeff: 0.4403 - precision: 0.6848 - recall: 0.6196 - val_loss: 0.6490 - val_dice_loss: 0.4513 - val_iou_coeff: 0.4038 - val_precision: 0.8161 - val_recall: 0.4445\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T11:15:36.655065Z",
          "iopub.execute_input": "2021-07-02T11:15:36.655542Z",
          "iopub.status.idle": "2021-07-02T13:21:07.219812Z",
          "shell.execute_reply.started": "2021-07-02T11:15:36.655497Z",
          "shell.execute_reply": "2021-07-02T13:21:07.218836Z"
        },
        "trusted": true,
        "id": "c7mjPxVwLZF3",
        "outputId": "cf4961df-ad01-49f5-fd12-d910e42ae75f"
      },
      "source": [
        "    model.fit(train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=30,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks,\n",
        "        shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/30\n350/350 [==============================] - 249s 710ms/step - loss: 0.5363 - dice_loss: 0.3371 - iou_coeff: 0.5110 - precision: 0.7182 - recall: 0.6970 - val_loss: 0.5006 - val_dice_loss: 0.3081 - val_iou_coeff: 0.5413 - val_precision: 0.7985 - val_recall: 0.6474\nEpoch 2/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.5143 - dice_loss: 0.3243 - iou_coeff: 0.5293 - precision: 0.7277 - recall: 0.7082 - val_loss: 0.5027 - val_dice_loss: 0.3123 - val_iou_coeff: 0.5445 - val_precision: 0.8357 - val_recall: 0.6224\nEpoch 3/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.5014 - dice_loss: 0.3111 - iou_coeff: 0.5423 - precision: 0.7289 - recall: 0.7306 - val_loss: 0.4274 - val_dice_loss: 0.2548 - val_iou_coeff: 0.6075 - val_precision: 0.7591 - val_recall: 0.7803\nEpoch 4/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4707 - dice_loss: 0.2920 - iou_coeff: 0.5698 - precision: 0.7612 - recall: 0.7273 - val_loss: 0.4650 - val_dice_loss: 0.2858 - val_iou_coeff: 0.5735 - val_precision: 0.8224 - val_recall: 0.6778\nEpoch 5/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4507 - dice_loss: 0.2737 - iou_coeff: 0.5866 - precision: 0.7655 - recall: 0.7465 - val_loss: 0.4902 - val_dice_loss: 0.3118 - val_iou_coeff: 0.5490 - val_precision: 0.8299 - val_recall: 0.6374\nEpoch 6/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4814 - dice_loss: 0.3057 - iou_coeff: 0.5612 - precision: 0.7483 - recall: 0.7158 - val_loss: 0.6416 - val_dice_loss: 0.4563 - val_iou_coeff: 0.4188 - val_precision: 0.7570 - val_recall: 0.4710\nEpoch 7/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4402 - dice_loss: 0.2646 - iou_coeff: 0.5965 - precision: 0.7740 - recall: 0.7585 - val_loss: 0.6693 - val_dice_loss: 0.4453 - val_iou_coeff: 0.4001 - val_precision: 0.4615 - val_recall: 0.8255\nEpoch 8/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4454 - dice_loss: 0.2724 - iou_coeff: 0.5917 - precision: 0.7722 - recall: 0.7500 - val_loss: 0.4227 - val_dice_loss: 0.2562 - val_iou_coeff: 0.6107 - val_precision: 0.7846 - val_recall: 0.7494\nEpoch 9/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4156 - dice_loss: 0.2481 - iou_coeff: 0.6177 - precision: 0.7865 - recall: 0.7734 - val_loss: 0.3980 - val_dice_loss: 0.2333 - val_iou_coeff: 0.6341 - val_precision: 0.8424 - val_recall: 0.7417\nEpoch 10/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3910 - dice_loss: 0.2293 - iou_coeff: 0.6404 - precision: 0.8021 - recall: 0.7844 - val_loss: 0.4156 - val_dice_loss: 0.2486 - val_iou_coeff: 0.6178 - val_precision: 0.8114 - val_recall: 0.7452\nEpoch 11/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.4373 - dice_loss: 0.2637 - iou_coeff: 0.5997 - precision: 0.7807 - recall: 0.7575 - val_loss: 0.4193 - val_dice_loss: 0.2510 - val_iou_coeff: 0.6125 - val_precision: 0.7495 - val_recall: 0.8017\nEpoch 12/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3942 - dice_loss: 0.2309 - iou_coeff: 0.6383 - precision: 0.8009 - recall: 0.7869 - val_loss: 0.4108 - val_dice_loss: 0.2456 - val_iou_coeff: 0.6239 - val_precision: 0.8225 - val_recall: 0.7423\nEpoch 13/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3677 - dice_loss: 0.2123 - iou_coeff: 0.6613 - precision: 0.8143 - recall: 0.8040 - val_loss: 0.4310 - val_dice_loss: 0.2542 - val_iou_coeff: 0.6072 - val_precision: 0.7628 - val_recall: 0.7657\nEpoch 14/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3795 - dice_loss: 0.2186 - iou_coeff: 0.6539 - precision: 0.8144 - recall: 0.7927 - val_loss: 0.3884 - val_dice_loss: 0.2250 - val_iou_coeff: 0.6437 - val_precision: 0.8029 - val_recall: 0.7882\nEpoch 15/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3679 - dice_loss: 0.2122 - iou_coeff: 0.6615 - precision: 0.8140 - recall: 0.8060 - val_loss: 0.4184 - val_dice_loss: 0.2510 - val_iou_coeff: 0.6157 - val_precision: 0.8414 - val_recall: 0.7183\nEpoch 16/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3695 - dice_loss: 0.2131 - iou_coeff: 0.6607 - precision: 0.8159 - recall: 0.8048 - val_loss: 0.4555 - val_dice_loss: 0.2865 - val_iou_coeff: 0.5792 - val_precision: 0.8164 - val_recall: 0.6966\nEpoch 17/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3509 - dice_loss: 0.2025 - iou_coeff: 0.6770 - precision: 0.8327 - recall: 0.8068 - val_loss: 0.3975 - val_dice_loss: 0.2320 - val_iou_coeff: 0.6370 - val_precision: 0.8133 - val_recall: 0.7675\nEpoch 18/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3635 - dice_loss: 0.2112 - iou_coeff: 0.6654 - precision: 0.8203 - recall: 0.8050 - val_loss: 0.4084 - val_dice_loss: 0.2483 - val_iou_coeff: 0.6239 - val_precision: 0.8468 - val_recall: 0.7238\nEpoch 19/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3868 - dice_loss: 0.2266 - iou_coeff: 0.6444 - precision: 0.8073 - recall: 0.7920 - val_loss: 0.4318 - val_dice_loss: 0.2573 - val_iou_coeff: 0.6064 - val_precision: 0.7848 - val_recall: 0.7522\nEpoch 20/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3412 - dice_loss: 0.1934 - iou_coeff: 0.6856 - precision: 0.8300 - recall: 0.8219 - val_loss: 0.3940 - val_dice_loss: 0.2320 - val_iou_coeff: 0.6373 - val_precision: 0.7948 - val_recall: 0.7837\nEpoch 21/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3295 - dice_loss: 0.1867 - iou_coeff: 0.6965 - precision: 0.8395 - recall: 0.8278 - val_loss: 0.4028 - val_dice_loss: 0.2403 - val_iou_coeff: 0.6323 - val_precision: 0.8442 - val_recall: 0.7361\nEpoch 22/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3301 - dice_loss: 0.1875 - iou_coeff: 0.6966 - precision: 0.8394 - recall: 0.8197 - val_loss: 0.4008 - val_dice_loss: 0.2353 - val_iou_coeff: 0.6328 - val_precision: 0.7880 - val_recall: 0.7825\nEpoch 23/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3191 - dice_loss: 0.1801 - iou_coeff: 0.7052 - precision: 0.8419 - recall: 0.8351 - val_loss: 0.3793 - val_dice_loss: 0.2173 - val_iou_coeff: 0.6544 - val_precision: 0.7814 - val_recall: 0.8233\nEpoch 24/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3050 - dice_loss: 0.1697 - iou_coeff: 0.7188 - precision: 0.8471 - recall: 0.8441 - val_loss: 0.3947 - val_dice_loss: 0.2287 - val_iou_coeff: 0.6418 - val_precision: 0.7677 - val_recall: 0.8180\nEpoch 25/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.2739 - dice_loss: 0.1489 - iou_coeff: 0.7472 - precision: 0.8668 - recall: 0.8615 - val_loss: 0.3814 - val_dice_loss: 0.2179 - val_iou_coeff: 0.6539 - val_precision: 0.8071 - val_recall: 0.7942\nEpoch 26/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.2784 - dice_loss: 0.1526 - iou_coeff: 0.7434 - precision: 0.8642 - recall: 0.8600 - val_loss: 0.4403 - val_dice_loss: 0.2595 - val_iou_coeff: 0.6010 - val_precision: 0.7581 - val_recall: 0.7674\nEpoch 27/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3222 - dice_loss: 0.1803 - iou_coeff: 0.7042 - precision: 0.8394 - recall: 0.8341 - val_loss: 0.4569 - val_dice_loss: 0.2773 - val_iou_coeff: 0.5822 - val_precision: 0.6991 - val_recall: 0.8037\nEpoch 28/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.3251 - dice_loss: 0.1845 - iou_coeff: 0.7008 - precision: 0.8370 - recall: 0.8296 - val_loss: 0.3704 - val_dice_loss: 0.2120 - val_iou_coeff: 0.6613 - val_precision: 0.8113 - val_recall: 0.8031\nEpoch 29/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.2645 - dice_loss: 0.1424 - iou_coeff: 0.7563 - precision: 0.8749 - recall: 0.8643 - val_loss: 0.4072 - val_dice_loss: 0.2409 - val_iou_coeff: 0.6336 - val_precision: 0.8273 - val_recall: 0.7364\nEpoch 30/30\n350/350 [==============================] - 248s 709ms/step - loss: 0.2547 - dice_loss: 0.1363 - iou_coeff: 0.7655 - precision: 0.8799 - recall: 0.8706 - val_loss: 0.3825 - val_dice_loss: 0.2225 - val_iou_coeff: 0.6533 - val_precision: 0.8045 - val_recall: 0.7970\n",
          "output_type": "stream"
        },
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f0ae40fba50>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-07-02T13:23:39.919686Z",
          "iopub.execute_input": "2021-07-02T13:23:39.920036Z",
          "iopub.status.idle": "2021-07-02T14:47:19.390156Z",
          "shell.execute_reply.started": "2021-07-02T13:23:39.920002Z",
          "shell.execute_reply": "2021-07-02T14:47:19.387931Z"
        },
        "trusted": true,
        "id": "6une9Be6LZF3",
        "outputId": "91965185-68d0-42d1-8e80-59d18cfb8a4f"
      },
      "source": [
        "\n",
        "    model.fit(train_dataset,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=20,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks,\n",
        "        shuffle = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/20\n350/350 [==============================] - 248s 710ms/step - loss: 0.2308 - dice_loss: 0.1223 - iou_coeff: 0.7867 - precision: 0.8940 - recall: 0.8832 - val_loss: 0.3842 - val_dice_loss: 0.2253 - val_iou_coeff: 0.6517 - val_precision: 0.8241 - val_recall: 0.7731\nEpoch 2/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2138 - dice_loss: 0.1118 - iou_coeff: 0.8030 - precision: 0.9028 - recall: 0.8934 - val_loss: 0.3845 - val_dice_loss: 0.2212 - val_iou_coeff: 0.6536 - val_precision: 0.8127 - val_recall: 0.7896\nEpoch 3/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2020 - dice_loss: 0.1052 - iou_coeff: 0.8137 - precision: 0.9099 - recall: 0.8995 - val_loss: 0.3800 - val_dice_loss: 0.2187 - val_iou_coeff: 0.6565 - val_precision: 0.8435 - val_recall: 0.7674\nEpoch 4/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2077 - dice_loss: 0.1082 - iou_coeff: 0.8091 - precision: 0.9056 - recall: 0.8975 - val_loss: 0.3848 - val_dice_loss: 0.2222 - val_iou_coeff: 0.6519 - val_precision: 0.8323 - val_recall: 0.7690\nEpoch 5/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2732 - dice_loss: 0.1515 - iou_coeff: 0.7496 - precision: 0.8736 - recall: 0.8557 - val_loss: 0.4040 - val_dice_loss: 0.2299 - val_iou_coeff: 0.6373 - val_precision: 0.8421 - val_recall: 0.7460\nEpoch 6/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2223 - dice_loss: 0.1168 - iou_coeff: 0.7953 - precision: 0.8985 - recall: 0.8892 - val_loss: 0.3947 - val_dice_loss: 0.2280 - val_iou_coeff: 0.6409 - val_precision: 0.8307 - val_recall: 0.7580\nEpoch 7/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2117 - dice_loss: 0.1112 - iou_coeff: 0.8048 - precision: 0.9033 - recall: 0.8959 - val_loss: 0.3971 - val_dice_loss: 0.2292 - val_iou_coeff: 0.6426 - val_precision: 0.8323 - val_recall: 0.7603\nEpoch 8/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1827 - dice_loss: 0.0944 - iou_coeff: 0.8314 - precision: 0.9199 - recall: 0.9109 - val_loss: 0.3893 - val_dice_loss: 0.2225 - val_iou_coeff: 0.6500 - val_precision: 0.8013 - val_recall: 0.7959\nEpoch 9/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1729 - dice_loss: 0.0890 - iou_coeff: 0.8404 - precision: 0.9258 - recall: 0.9158 - val_loss: 0.3999 - val_dice_loss: 0.2281 - val_iou_coeff: 0.6425 - val_precision: 0.8206 - val_recall: 0.7707\nEpoch 10/20\n350/350 [==============================] - 248s 708ms/step - loss: 0.1744 - dice_loss: 0.0897 - iou_coeff: 0.8395 - precision: 0.9261 - recall: 0.9147 - val_loss: 0.3995 - val_dice_loss: 0.2302 - val_iou_coeff: 0.6411 - val_precision: 0.8379 - val_recall: 0.7522\nEpoch 11/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1706 - dice_loss: 0.0866 - iou_coeff: 0.8437 - precision: 0.9258 - recall: 0.9185 - val_loss: 0.3840 - val_dice_loss: 0.2202 - val_iou_coeff: 0.6541 - val_precision: 0.8280 - val_recall: 0.7723\nEpoch 12/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1598 - dice_loss: 0.0816 - iou_coeff: 0.8526 - precision: 0.9319 - recall: 0.9242 - val_loss: 0.3831 - val_dice_loss: 0.2179 - val_iou_coeff: 0.6557 - val_precision: 0.8214 - val_recall: 0.7858\nEpoch 13/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1521 - dice_loss: 0.0773 - iou_coeff: 0.8597 - precision: 0.9357 - recall: 0.9290 - val_loss: 0.4079 - val_dice_loss: 0.2375 - val_iou_coeff: 0.6346 - val_precision: 0.8418 - val_recall: 0.7355\nEpoch 14/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1505 - dice_loss: 0.0761 - iou_coeff: 0.8615 - precision: 0.9374 - recall: 0.9289 - val_loss: 0.3987 - val_dice_loss: 0.2295 - val_iou_coeff: 0.6439 - val_precision: 0.8339 - val_recall: 0.7565\nEpoch 15/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1570 - dice_loss: 0.0788 - iou_coeff: 0.8564 - precision: 0.9341 - recall: 0.9257 - val_loss: 0.3940 - val_dice_loss: 0.2246 - val_iou_coeff: 0.6477 - val_precision: 0.8181 - val_recall: 0.7757\nEpoch 16/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2552 - dice_loss: 0.1419 - iou_coeff: 0.7674 - precision: 0.8852 - recall: 0.8676 - val_loss: 0.4246 - val_dice_loss: 0.2520 - val_iou_coeff: 0.6117 - val_precision: 0.7514 - val_recall: 0.7937\nEpoch 17/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.2772 - dice_loss: 0.1543 - iou_coeff: 0.7458 - precision: 0.8739 - recall: 0.8558 - val_loss: 0.4008 - val_dice_loss: 0.2286 - val_iou_coeff: 0.6410 - val_precision: 0.7761 - val_recall: 0.8033\nEpoch 18/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1604 - dice_loss: 0.0818 - iou_coeff: 0.8521 - precision: 0.9322 - recall: 0.9234 - val_loss: 0.3972 - val_dice_loss: 0.2232 - val_iou_coeff: 0.6468 - val_precision: 0.7676 - val_recall: 0.8255\nEpoch 19/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1400 - dice_loss: 0.0704 - iou_coeff: 0.8712 - precision: 0.9424 - recall: 0.9349 - val_loss: 0.3980 - val_dice_loss: 0.2256 - val_iou_coeff: 0.6467 - val_precision: 0.7948 - val_recall: 0.7973\nEpoch 20/20\n350/350 [==============================] - 248s 709ms/step - loss: 0.1299 - dice_loss: 0.0648 - iou_coeff: 0.8807 - precision: 0.9480 - recall: 0.9401 - val_loss: 0.4017 - val_dice_loss: 0.2289 - val_iou_coeff: 0.6432 - val_precision: 0.8161 - val_recall: 0.7694\n",
          "output_type": "stream"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f06e6957690>"
          },
          "metadata": {}
        }
      ]
    }
  ]
}